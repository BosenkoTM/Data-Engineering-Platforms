
# Лабораторная работа 3.1. Создание интерактивного аналитического дашборда на основе витрин данных

### Цель работы
пройти полный цикл data-driven исследования: от сбора первичных данных с помощью онлайн-опроса по актуальной теме Data Engineering до создания интерактивного аналитического дашборда для визуализации и интерпретации полученных результатов в Yandex DataLens. В качестве альтернативы или для углубленного изучения, провести анализ с использованием Tableau.

### Инструменты и методология
*   лекция "Современный Business Intelligence и его реализация на платформе Yandex DataLens".
*   обучающие курсы и материалы по Yandex DataLens: https://yandex.cloud/ru/docs/datalens/training
*   официальный сайт Yandex DataLens: https://datalens.ru/
*   официальный сайт Tableau: https://tableau.com

### Задачи
1.	Сформулировать исследовательскую проблему по одной из предложенных тем и спроектировать методологически корректный опрос для сбора первичных данных.
2.	Провести опрос среди целевой аудитории, собрать и подготовить (очистить) полученные данные для анализа.
3.	Реализовать data-driven решение, разработав интерактивный аналитический дашборд в Yandex DataLens для визуального представления результатов опроса.
4.	Проинтерпретировать визуализированные данные и сформулировать 3-5 ключевых выводов, отвечающих на исследовательские вопросы.
5.	Задокументировать и представить результаты своей работы в виде структурированного Git-репозитория, включающего все артефакты проекта.

### ПО и облачные инструменты
*	**Сбор данных:** Google Forms или Survey Monkey.
*	**Анализ и Визуализация:**
    *   основной инструмент: Yandex DataLens.
    *   альтернативный инструмент: Tableau (Public / Desktop).
    *   инструмент для предобработки (опционально): Jupyter Notebook (Python) или R Markdown.
*	**Система контроля версий:** Git.

---

### Ход работы

#### Этап 1. Проектирование и создание опроса
*	**Выбор темы:** выберите одну тему из таблицы "Варианты тем для опроса" ниже.
*	**Изучение материалов:** ознакомьтесь с материалами из теоретической базы, чтобы сформулировать глубокие и релевантные вопросы.
*	**Разработка вопросов:**
    *   создайте 10-15 вопросов различных типов (множественный выбор, шкала Лайкерта, ранжирование, открытые вопросы).
    *   вопросы должны быть четкими, недвусмысленными и соответствовать профессиональному уровню.
*	**Создание формы:** реализуйте опрос с помощью Google Forms или Survey Monkey.

#### Этап 2. Сбор и подготовка данных
*	**Распространение опроса:** проведите опрос среди минимум 5 респондентов (например, сокурсники, коллеги, участники профессиональных сообществ).
*	**Экспорт данных:** выгрузите результаты опроса в формате CSV или Excel.
*	**Подготовка витрины данных:** проведите очистку и предобработку данных. Это может включать исправление опечаток в открытых ответах, приведение данных к единому формату, кодирование категориальных переменных. Этот этап можно выполнить с помощью Python/R или непосредственно в BI-инструменте.

#### Этап 3. Реализация дашборда в Yandex DataLens
*	**Подключение к источнику данных:** создайте в DataLens подключение к вашему итоговому CSV-файлу с очищенными данными.
*	**Создание датасета:** настройте типы данных для всех полей, дайте им понятные названия.
*	**Разработка чартов:** для каждого значимого вопроса из вашего опроса создайте подходящую визуализацию (например, круговая диаграмма для распределения ответов, столбчатая диаграмма для сравнения, таблицы для открытых ответов). Всего должно быть создано не менее 3-х различных визуализаций.
*	**Сборка дашборда:**
    -	создайте новый дашборд и разместите на нем разработанные чарты.
    -	добавьте заголовок и текстовые блоки с описанием цели исследования и ключевых сегментов аудитории.
    -	если применимо, добавьте селекторы для интерактивной фильтрации данных (например, по опыту работы респондентов).

#### Этап 4. Формулирование выводов
На основе визуализаций на дашборде, проанализируйте полученные результаты и сформулируйте 3-5 основных выводов или инсайтов по теме вашего исследования.

#### Этап 5. Публикация результатов
Загрузите все материалы проекта в публичный Git-репозиторий. Структура репозитория должна включать:
*	`README.md`: Краткое описание проекта, цели, процесса, ключевые выводы и **активная ссылка** на ваш дашборд в Yandex DataLens.
*	Папку `/survey` с PDF-версией или скриншотами созданного опроса.
*	Папку `/data` с исходными (*raw*) и очищенными (*processed*) данными опроса в CSV/Excel.
*	Папку `/analysis` с Jupyter Notebook или R Markdown, если они использовались для предобработки (опционально).
*	Папку `/report` с отчетом по лабораторной работе в формате PDF.

---

### Требования к отчету
1.	**Введение:** постановка цели, описание выбранной темы и целевой аудитории опроса.
2.	**Процесс разработки:** описание шагов по созданию опроса, сбору данных и разработке дашборда с ключевыми скриншотами.
3.	**Анализ результатов:** представление разработанных визуализаций и их интерпретация.
4.	**Выводы:** детальное изложение 3-5 ключевых выводов, сделанных на основе анализа.
5.	**Заключение:** общие выводы по проделанной работе и полученному опыту.
6.	**Ссылки:** активная ссылка на Git-репозиторий с работой.

### Критерии оценки
*	**Качество и релевантность опроса (30%):** вопросы глубокие, профессионально сформулированные, соответствуют выбранной теме.
*	**Аналитическая глубина дашборда и выводов (30%):** дашборд наглядно представляет результаты, выводы логичны, обоснованы и отвечают на исследовательские вопросы.
*	**Качество визуализаций (20%):** выбраны подходящие типы визуализаций, они корректно настроены, легко читаются и эстетически оформлены.
*	**Качество отчета и Git-репозитория (20%):** отчет и репозиторий хорошо структурированы, оформлены согласно требованиям, все артефакты на месте.

### Примечание по оценке
*	**Основной путь:** выполнение работы в Yandex DataLens.
*	**Альтернативный путь/Бонус:** работа, выполненная в Tableau, или наличие дашбордов в обоих инструментах для сравнения, может быть оценена выше.
*	**При отсутствии респондентов:** допускается создание гипотетического набора данных (mock data) с четким обоснованием в отчете, почему ответы распределены именно таким образом.

---

### Варианты тем для опроса

| № | Тема для опроса |
|---|---|
| 1 | Современные ETL/ELT инструменты и их эффективность |
| 2 | Проблемы качества данных в корпоративной среде |
| 3 | Хранилища данных: современные подходы и архитектуры |
| 4 | Технологии Big Data в бизнес-процессах |
| 5 | Data Governance: практики и вызовы |
| 6 | Роль Data Engineer в современной организации |
| 7 | Облачные решения для работы с данными |
| 8 | Реализация Data Lake в компаниях |
| 9 | Проблемы безопасности данных в Data Engineering |
| 10 | Автоматизация процессов работы с данными |
| 11 | Data Mesh: принципы и применение |
| 12 | Технический долг в системах работы с данными |
| 13 | Batch vs Real-time processing: выбор подхода |
| 14 | Интеграция данных из разнородных источников |
| 15 | Метаданные и их управление |
| 16 | Версионирование данных и кода в Data Engineering |
| 17 | MLOps и его связь с Data Engineering |
| 18 | Мониторинг пайплайнов данных |
| 19 | Масштабирование систем хранения и обработки данных |
| 20 | Организация командной работы в Data Engineering проектах |
| 21 | Data Catalog: внедрение и использование |
| 22 | Оптимизация производительности запросов и пайплайнов |
| 23 | Оркестрация рабочих процессов с данными |
| 24 | Микросервисная архитектура для работы с данными |
| 25 | Serverless архитектура в Data Engineering |
| 26 | Стратегии обработки ошибок в пайплайнах данных |
| 27 | DataOps: практики и инструменты |
| 28 | Тестирование в Data Engineering |
| 29 | Обработка потоковых данных: инструменты и подходы |
| 30 | Управление затратами в системах работы с данными |
| 31 | Этические аспекты работы с данными |
| 32 | Компетенции современного Data Engineer |
| 33 | Изменение данных (CDC): методы и инструменты |
| 34 | Интеграция AI/ML в процессы Data Engineering |
| 35 | Внедрение Data Mesh в организации |
````
