# Аналитика и инженерия данных в облаке: от архитектуры до оркестрации

Рассмотриваются современные подходы к построению аналитических систем в облаке, фокусируясь на ключевых трендах, архитектурах и роли Cloud Composer (Apache Airflow) в автоматизации конвейеров данных.

## 1. Cloud Computing для аналитиков: тренды и архитектуры

Облачные платформы, такие как Google Cloud Platform (GCP), фундаментально изменили инженерию и аналитику данных. Они предоставили инструменты для работы с данными любого масштаба без необходимости управлять физической инфраструктурой.

**Ключевая роль облачных систем:**
- **Эластичность и масштабируемость.** Возможность динамически выделять и освобождать вычислительные ресурсы, оплачивая только то, что используется.
- **Управляемые сервисы (Managed Services).** Провайдер берет на себя задачи по установке, настройке и поддержке ПО (например, Cloud Composer управляет Airflow, а BigQuery — хранилищем данных), позволяя командам сосредоточиться на бизнес-логике.
- **Интегрированная экосистема.** Сервисы для хранения (GCS), обработки (Dataflow), хранения (BigQuery) и оркестрации (Composer) тесно интегрированы, что упрощает построение end-to-end решений.

### Основные тренды и архитектуры

| Тренд / Архитектура | Описание | Роль в GCP |
| :--- | :--- | :--- |
| **Serverless ("Бессерверная")** | Модель, при которой облачный провайдер полностью управляет серверами. Разработчики не думают об инфраструктуре, а фокусируются на коде. | **BigQuery** — бессерверное хранилище данных. **Cloud Functions** — для событийной обработки данных. |
| **Lakehouse** | Современная архитектура, объединяющая гибкость **Data Lake** (хранение необработанных данных) и производительность **Data Warehouse** (структурированные данные для аналитики). | **Cloud Storage** выступает как Data Lake. **BigQuery** — как Data Warehouse, способный напрямую запрашивать данные из GCS. |
| **Искусственный интеллект (ИИ) и ML** | ИИ становится не просто потребителем данных, а частью аналитического конвейера для прогнозирования, классификации и поиска аномалий. | **BigQuery ML** позволяет создавать и обучать модели машинного обучения с помощью SQL прямо внутри хранилища. **Vertex AI** — полноценная платформа для ML-разработки. |

## 2. Оркестрация пакетных ETL-процессов с помощью Cloud Composer

В современной облачной архитектуре ключевую роль играет **оркестратор** — инструмент, который управляет запуском, зависимостями и мониторингом конвейеров данных. В GCP эту роль выполняет **Cloud Composer**.

| Концепция | Описание | Как управляется в Cloud Composer |
| :--- | :--- | :--- |
| **DAG (Directed Acyclic Graph)** | "Мозг" рабочего процесса, написанный на Python. Определяет, какие задачи и в каком порядке выполнять. | Файлы с DAG'ами хранятся в GCS-бакете, откуда Composer их автоматически считывает и планирует. |
| **Operator** | "Строительный блок" DAG'а, определяющий одну задачу (например, запустить SQL, выполнить Bash-скрипт). | Composer поставляется с предустановленными провайдерами для всех ключевых сервисов GCP. |

### Эволюция DAG: от простого к продвинутому

| Уровень | Основная цель | Ключевые концепции и технологии GCP |
| :--- | :--- | :--- |
| **Level 1-2** | **Базовый ELT-пайплайн** | Использование нативных операторов (`GCSToBigQueryOperator`, `BigQueryInsertJobOperator`) для перемещения и трансформации данных. |
| **Level 3** | **Параметризация** | Использование переменных Airflow и макросов (`{{ ds }}`) для создания гибких DAG'ов, работающих с разными средами и датами. |
| **Level 4** | **Идемпотентность** | Гарантия того, что повторный запуск задачи дает тот же результат. Критически важно для надежности. |
| **Level 5** | **Меж-DAG'овые зависимости** | Создание конвейеров, которые запускаются по факту обновления данных другими конвейерами. |

---

## 3. Современные подходы и лучшие практики в облаке

### Идемпотентность с помощью партиционирования BigQuery

**Проблема.** Использование `WRITE_APPEND` при повторном запуске DAG'а приводит к дублированию данных.

**Современное облачное решение.** Использовать партиционированные таблицы в BigQuery.
- **Целевая таблица.** Динамически формируется с помощью макроса Airflow, например `my_table$20230101`.
- **Оператор `GCSToBigQueryOperator`.**
  - `write_disposition='WRITE_TRUNCATE'` перезаписывает данные **только для целевой партиции**, не затрагивая остальные данные.
  - `time_partitioning` определяет поле для партиционирования.

### Data-Aware Scheduling с помощью Airflow Datasets

**Проблема.** Ненадежное планирование зависимых DAG'ов по фиксированному времени.

**Современное решение (Airflow 2.4+).** Использовать **Airflow Datasets**.
- **Upstream DAG (поставщик).** В последней задаче указывает `outlets=[Dataset("my_bigquery_table")]`, сигнализируя об обновлении данных.
- **Downstream DAG (потребитель).** В качестве расписания указывает `schedule=[Dataset("my_bigquery_table")]`, запускаясь только по этому сигналу.

### Сравнение версий Cloud Composer

| Характеристика | Cloud Composer 1 | Cloud Composer 2 (Современный подход) |
| :--- | :--- | :--- |
| **Архитектура** | Фиксированное количество worker'ов | **Автомасштабирование** worker'ов от нуля до максимума. |
| **Эффективность** | Постоянно потребляет ресурсы. | Экономически эффективнее, оплата только за используемые ресурсы. |
| **Рекомендация** | Устарел. | **Рекомендуется** для всех новых развертываний. |

---

### Практическая работа

-   [Практическая работа 4.1. Написание простого DAG для запуска dbt-проекта](pw_4_1.md)

### Список литературы

1.  [Официальная документация Apache Airflow](https://airflow.apache.org/docs/)
2.  [Документация Google Cloud Composer](https://cloud.google.com/composer/docs)
3.  [Документация по партиционированным таблицам в BigQuery](https://cloud.google.com/bigquery/docs/partitioned-tables)
4.  [Airflow Datasets (Data-aware scheduling)](https://airflow.apache.org/docs/apache-airflow/stable/concepts/datasets.html)


