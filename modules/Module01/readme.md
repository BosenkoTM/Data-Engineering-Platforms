# Модуль 1. Роль Аналитики в Организации

[Обратно в содержание курса :leftwards_arrow_with_hook:](https://github.com/BosenkoTM/Data-Engineering-Platforms/blob/master/readme.md) 

В процессе этого модуля  познакомимся с предметом изучения, узнаем кто такой `Data Engineer` и что он делает, и как его еще называют. Главное, поймем, как он помогает бизнесу быть эффективней и зарабатывать деньги. Рассмотрим типовые архитектуры аналитических решений

## 1.1. Введение

Данный модуль направлен на получение теоретической базы знаний для дальнейшей работы с курсом, а также на понимание роли аналитики и дата инженера в организации. Прежде чем научиться работать с инструментами очень важно понять принцип работы бизнеса, как бизнес использует данные, и как они могут быть полезны. Будут рассмотрены типовые архитектурные решения и вакансии на роль дата инженера.


## 1.2. Роль аналитики в организации 

Организация существует для того, чтобы приносить какую-либо ценность (value). Выделяют 3 ключевых группы, кому именно может быть полезен тот или иной бизнес: 

1. Владельцы бизнеса (shareholders); 

2. Сотрудники (employees); 

3. Клиенты (customers). 

![Analytics Value Chain](https://rockyourdata.cloud/wp-content/uploads/2019/02/Screen-Shot-2019-02-11-at-8.58.28-PM.png)

В современной бизнес-парадигме клиенты являются центральной группой заинтересованных лиц, поскольку многие успешные компании работают по принципу "customer centricity" (клиентоцентричности) или "customer obsession" (одержимости клиентом).

Для устойчивого роста бизнеса необходимо создавать дополнительную ценность для каждой из групп. Для клиентов это может быть улучшение клиентского опыта (customer experience), персонализация услуг, повышение качества продуктов. Для сотрудников — карьерный рост, справедливая оплата труда, баланс между работой и личной жизнью (work-life balance). Для владельцев — рост прибыли, увеличение капитализации, дивиденды.

Все группы заинтересованных лиц принимают решения (decision making) для достижения своих целей. Качественные решения требуют надежных данных. **Данные могут существовать в различных формах**: 

1. необработанные данные (raw data), 
2. структурированная информация (organized data), 
3. аналитические инсайты (insights),
4. знания (knowledge). 

**Ключевая задача инженера данных** заключается в обеспечении всех заинтересованных групп качественными, актуальными и доступными данными для принятия обоснованных решений. Поэтому критически важно понимать, как работа инженера данных влияет на операционную эффективность и стратегическое развитие бизнеса.


## 1.3. Задачи аналитики

Аналитика это такая часть бизнеса, которая использует данные для получения информации, на основе которой принимаются решения для эффективной работы бизнеса. Аналитика нужна для: 

1. **Увеличение доходов и оптимизация прибыли**. Аналитические решения должны демонстрировать измеримый вклад в финансовые показатели компании;
2. **Оптимизация операционных расходов**. Систематический мониторинг и анализ затрат для выявления возможностей экономии;
3. **Исследование и освоение новых рынков**. Анализ рыночных трендов, потребительского поведения и конкурентного ландшафта;
4. **Обеспечение соответствия требованиям (compliance)**. Контроль соблюдения нормативных требований и внутренних стандартов;
5. **Управление рисками**. Идентификация, оценка и мониторинг бизнес-рисков;
6. **Поддержка инновационной деятельности**. Анализ данных для разработки новых продуктов и услуг.


## 1.4. MindMap инжиниринга данных

Интеллектуальная карта (`MindMap`) — это инструмент визуального структурирования информации и знаний, который помогает системно представить ключевые области инжиниринга данных.

![Mindmap](https://user-images.githubusercontent.com/65634544/83002336-4a252e80-a050-11ea-884a-aad96a181f74.jpg)

**Основные компоненты современного инжиниринга данных:**

1. **Интеграция данных**. ETL (Extract, Transform, Load) и ELT (Extract, Load, Transform) процессы для извлечения, трансформации и загрузки данных;
2. **Платформы данных**. Современные архитектуры включают хранилища данных (Data Warehouse), озера данных (Data Lake) и гибридные платформы данных (Data Lakehouse);
3. **Облачные технологии**. Cloud-native решения для масштабируемой аналитики (AWS, Azure, GCP);
4. **Модели обработки данных**:
   - **Пакетная обработка (Batch processing)** — классическая модель ETL для больших объемов данных
   - **Потоковая обработка (Stream processing)** — обработка данных в реальном времени;
5. **Бизнес-интеллект (Business Intelligence)**. Прослойка между техническими системами и бизнес-пользователями;
6. **SQL (Structured Query Language)**. Универсальный язык для работы с реляционными данными;
7. **Языки программирования**. Python, Java, Scala для разработки data pipelines и аналитических решений;
8. **MPP (Massively Parallel Processing)**. Архитектурная особенность современных аналитических СУБД для обработки больших объемов данных;
9. **Технологии Big Data**. Hadoop ecosystem, NoSQL базы данных;
10. **Apache Spark**. Унифицированная платформа для распределенной обработки данных.

## 1.5. Основные роли в аналитике

### Традиционная категория:

1. **BI-разработчик**. Создание отчетов, дашбордов, внедрение BI-решений (Tableau, Power BI, SAP BusinessObjects). Предоставление бизнес-рекомендаций (business insights);
2. **ETL/ELT разработчик**. Разработка процессов интеграции данных;
3. **Разработчик отчетов** = BI-инженер. Создание и поддержка аналитических отчетов;
4. **DW разработчик/архитектор**. Проектирование и разработка архитектуры хранилищ данных;
5. **Специалист по моделированию данных (Data Modeler)**. Анализ бизнес-процессов и создание концептуальных, логических и физических моделей данных.

### Категория инженера данных:
1. **Data Engineer** (классическое понимание). Разработка и поддержка инфраструктуры данных;
2. **Big Data инженер**. Работа с распределенными системами и NoSQL технологиями;
3. **Cloud Data Engineer**. Специализация на облачных платформах данных;
4. **Data Platform инженер**. Создание и управление комплексными платформами данных;
5. **MLOps Engineer**. Инженер по внедрению и сопровождению ML-моделей в продакшене.

### Роли в области Data Science и разработки:
1. **Software Development Engineer**. Разработчик ПО с экспертизой в области данных;
2. **Machine Learning Engineer**. Инженер по машинному обучению;
3. **Data Visualization Engineer**. Специалист по визуализации данных с использованием программных инструментов;
4. **Applied Scientist**. Прикладной исследователь;
5. **Research Scientist**. Научный сотрудник в области данных.

### Категория продвинутая аналитика (Элементы прогнозирования):
1. Data mining. Роль до Data science;
2. Data science. Хорошее знание математики, статистики, программирования;
3. Аналитик данных = Data science.

### Аналитические роли:
1. **Data Scientist**. Специалист по извлечению знаний из данных с использованием математических и статистических методов;
2. **Data Analyst**. Аналитик данных, фокус на описательной аналитике;
3. **Business Analyst**. Бизнес-аналитик, мостик между бизнесом и IT.

## 1.6. Два типа инженера данных
Термин "инженер" подразумевает системный подход к решению технических задач. Инженер — это профессионал, способный анализировать сложные системы, выявлять проблемы и создавать эффективные решения, используя профессиональный инструментарий и методологии.

### 1. Технический инженер данных (Technical Data Engineer)
**Профиль**: программист, эволюционировавший в сторону данных.
**Ключевые навыки**:
- Глубокое знание языков программирования (Python, Java, Scala).
- Понимание алгоритмов и структур данных.
- Опыт разработки распределенных систем.
- Знание принципов DevOps и CI/CD.

**Подход**: создание собственных решений "с нуля", оптимизация производительности, работа с низкоуровневыми API.

### 2. Продуктовый инженер данных (Product-Oriented Data Engineer)  
**Профиль**: BI/DW/ETL-разработчик, расширивший компетенции до современных технологий.
**Ключевые навыки**:
- Глубокое понимание бизнес-процессов.
- Экспертиза в области моделирования данных.
- Знание современных cloud-native инструментов.
- Навыки работы с готовыми платформами и сервисами.

**Подход**: быстрое достижение бизнес-результатов через интеграцию готовых решений, focus на пользовательский опыт.

### Универсальные компетенции
Независимо от профиля, современный инженер данных должен:
- Понимать принципы работы с различными типами данных.
- Уметь проектировать масштабируемые и надежные системы.
- Владеть основами облачных технологий.
- Понимать бизнес-контекст и уметь переводить бизнес-требования в технические решения.

**Философия курса**: фокусируемся не на механическом изучении синтаксиса конкретных инструментов, а на понимании фундаментальных принципов работы с данными, классификации технологий и методологий решения бизнес-задач. Конкретные технические детали всегда можно найти в документации — главное понимать, когда и для чего их применять.

## 1.7. Архитектура современного аналитического решения

![Overall-Architecture](https://user-images.githubusercontent.com/65634544/83002262-2feb5080-a050-11ea-93f1-3fe6196c973a.png)

**Многоуровневая архитектура аналитических систем:**

### 1. Слой источников данных (Source Layer)
- **OLTP системы** (Online Transactional Processing) — транзакционные системы, оптимизированные для быстрых операций создания, чтения, обновления и удаления данных
- **Внешние API** и веб-сервисы
- **Файловые системы** и SFTP серверы  
- **IoT устройства** и сенсоры
- **Логи приложений** и системные метрики

### 2. Слой обработки (Processing/Compute Layer)
- **ETL/ELT движки** для трансформации данных
- **Потоковые процессоры** (Apache Kafka, Apache Storm)
- **Вычислительные кластеры** (Apache Spark, Hadoop)
- **Serverless функции** для легковесной обработки

### 3. Слой хранения (Storage Layer)
**Подслои хранилища:**
- **Staging Area** — промежуточная зона для необработанных данных из источников
- **Data Lake** — масштабируемое файловое хранилище для данных в исходном формате
- **Data Warehouse** — структурированное хранилище с оптимизированными моделями данных
- **Data Marts** — специализированные витрины данных для конкретных бизнес-областей

### 4. Слой доступа к данным (Access Layer)  
- **BI платформы** (Tableau, Power BI, Looker, SAP BusinessObjects)
- **Self-service аналитика** и SQL интерфейсы
- **API для приложений** и интеграций
- **Machine Learning платформы**

### 5. Слой управления и мониторинга (Governance Layer)
- **Data Catalog** — каталогизация и документирование данных
- **Управление качеством данных** (Data Quality Management)
- **Безопасность и контроль доступа**
- **Мониторинг производительности** и SLA

## 1.8. Анализ рынка труда и карьерных возможностей

### Международные платформы поиска работы:
- **LinkedIn.com** — профессиональная сеть с высококачественными вакансиями.
- **Indeed.com** — глобальная платформа с возможностью выбора региона.
- **Glassdoor.com** — вакансии с информацией о компаниях и зарплатах.
- **Amazon.jobs** — корпоративный портал вакансий Amazon.

### Российские платформы:
- **HH.ru** — крупнейший российский ресурс поиска работы.
- **Habr Career** — специализированная платформа для IT-специалистов.
- **SuperJob.ru** — альтернативная платформа поиска работы.

*Примечание: данный раздел носит справочный характер и может быть дополнен актуальными тенденциями рынка труда.*

## 1.9. Основы работы с данными в Excel

Excel остается важным инструментом для понимания принципов работы с данными. В рамках данного раздела рассматриваются:
- Основные функции для анализа данных.
- Создание сводных таблиц (Pivot Tables).
- Базовая визуализация данных.
- Принципы нормализации и структурирования данных.

*Данный раздел является дополнительным и предназначен для слушателей с базовым уровнем владения Excel.*


## Лабораторная работа 1.1

### Задачи:
1 **Настройка инструментария**. Установка Git или создание аккаунта на `GitHub`, базовая настройка среды разработки.

2 **Проектирование архитектуры**. Создание диаграммы архитектуры аналитического решения в `draw.io` с описанием всех компонентов и потоков данных.

3 **Практическая работа с данными**. Создание аналитического дашборда на основе предоставленного датасета с использованием `Git` для версионирования.

Подробные инструкции по выполнению — [Лабораторная работа 1](https://github.com/BosenkoTM/Data-Engineering-Platforms/tree/master/modules/Module01/Lab%201.1).

## Индивидуальное задание

**Бизнес-контекст**. Компания специализируется на продаже мелкой бытовой техники через три канала: веб-приложение, колл-центр и физические магазины.

### Задание 1. Аналитические расчеты	
Дополните [исходный Excel-файл](https://github.com/BosenkoTM/Data-Engineering-Platforms/tree/master/modules/Module01/ind_1) листами с расчетными формулами:

- **Сравнительный анализ каналов продаж**:. Расчет и визуализация выручки и прибыли по каналам
- **Анализ среднего чека**. Вычисление средней стоимости покупки для каждого канала
- **Анализ товарного портфеля**. Выявление неэффективных товарных позиций (критерий: доля выручки ≤ 0,001% от общей выручки канала)
- **Тренд-анализ**. Расчет квартального прироста общей выручки компании (%)

### Задание 2. Бизнес-выводы	
- Аналитическая оценка эффективности деятельности компании.
- Рекомендации по оптимизации бизнес-процессов.
- Выводы оформить на отдельном листе `Excel` с обоснованием.
	
### Задание 3. Презентация результатов	
- Создание информативного слайда с ключевыми выводами и метриками.
- Использование современных принципов `data storytelling`.
- Итоговый результат представить в формате `PDF`.	

## Список литературы и источников

1. Кимбалл, Р. Хранилище данных. Руководство по проектированию / Р. Кимбалл, М. Росс. — М.: Вильямс, 2018. — 696 с.

2. Инмон, У. Построение хранилища данных / У. Инмон. — 4-е изд. — М.: Вильямс, 2019. — 576 с.

3. Клеппман, М. Высоконагруженные приложения. Программирование, масштабирование, поддержка / М. Клеппман. — СПб.: Питер, 2018. — 640 с.

4. Данаи, Д. Архитектура больших данных / Д. Данаи. — М.: ДМК Пресс, 2017. — 312 с.

5. Видеолекции "Школа анализа данных Яндекса" // VK Video: [https://vk.com/video/@yandex_data_school](https://vk.com/video/@yandex_data_school)


